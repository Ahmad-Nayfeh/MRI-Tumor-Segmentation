{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro_markdown_nb4",
   "metadata": {},
   "source": [
    "# Notebook 4: Inference and App Preparation\n",
    "\n",
    "### Objectives:\n",
    "1.  **Load the Best Model:** Load the saved weights of our winning model (`ResNetUNet`).\n",
    "2.  **Create an Inference Pipeline:** Develop a robust function that takes a single image file, preprocesses it, and runs it through the model to get a segmentation mask.\n",
    "3.  **Test the Pipeline:** Verify that our inference function works correctly on a sample image, creating the final logic we'll use in our Streamlit application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup_imports_markdown_nb4",
   "metadata": {},
   "source": [
    "## 1. Setup, Imports, and Path Definitions\n",
    "\n",
    "First, we import the necessary libraries and define our project paths. We also import our model architectures from the `src` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "setup_imports_code_nb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Root added to path: d:\\Coding\\GitHub\\MRI-Tumor-Segmentation\n",
      "Root Directory: d:\\Coding\\GitHub\\MRI-Tumor-Segmentation\n",
      "Models Directory: d:\\Coding\\GitHub\\MRI-Tumor-Segmentation\\models\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Define Project Directories ---\n",
    "try:\n",
    "    ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "except NameError:\n",
    "    ROOT_DIR = os.path.abspath(os.path.join(os.path.dirname('__file__'), '..'))\n",
    "\n",
    "# --- Add Project Root to Python Path ---\n",
    "# This is the crucial step that allows us to import from the 'src' directory\n",
    "if ROOT_DIR not in sys.path:\n",
    "    sys.path.append(ROOT_DIR)\n",
    "\n",
    "print(f\"Project Root added to path: {ROOT_DIR}\")\n",
    "\n",
    "# --- Import our custom models (this will now work)---\n",
    "from src.models import BaselineUNet, ResNetUNet, TransUNet\n",
    "\n",
    "MODELS_DIR = os.path.join(ROOT_DIR, 'models')\n",
    "FIGURES_DIR = os.path.join(ROOT_DIR, 'figures')\n",
    "\n",
    "# --- Set Device ---\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Root Directory: {ROOT_DIR}\")\n",
    "print(f\"Models Directory: {MODELS_DIR}\")\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_model_markdown_nb4",
   "metadata": {},
   "source": [
    "## 2. Load the Best Trained Model\n",
    "\n",
    "Based on our benchmark results, the `ResNetUNet` was the clear winner. We will now load its saved weights into a model instance and set it to evaluation mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "load_model_code_nb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded best model: ResNetUNet from d:\\Coding\\GitHub\\MRI-Tumor-Segmentation\\models\\ResNetUNet_best_model.pth\n"
     ]
    }
   ],
   "source": [
    "BEST_MODEL_NAME = 'ResNetUNet'\n",
    "model_path = os.path.join(MODELS_DIR, f'{BEST_MODEL_NAME}_best_model.pth')\n",
    "\n",
    "# Instantiate the model architecture\n",
    "model = ResNetUNet(in_channels=4, out_channels=1).to(DEVICE)\n",
    "\n",
    "# Load the saved weights\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device(DEVICE)))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "print(f\"Successfully loaded best model: {BEST_MODEL_NAME} from {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inference_pipeline_markdown_nb4",
   "metadata": {},
   "source": [
    "## 3. Create the Inference Pipeline\n",
    "\n",
    "Here we create a single, powerful function called `predict`. This function encapsulates all the necessary steps: opening an image, preprocessing it to match the training format, running inference, and post-processing the output mask. This is the core function we will use in our Streamlit app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "inference_pipeline_code_nb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================\n",
    "#             CREATE THE INFERENCE PIPELINE (CORRECTED)\n",
    "# =========================================================================\n",
    "\n",
    "def predict(model, npy_image_path, device):\n",
    "    \"\"\"\n",
    "    Runs the full inference pipeline on a single, preprocessed .npy image slice.\n",
    "    \"\"\"\n",
    "    # Load the correctly preprocessed numpy array\n",
    "    img_np = np.load(npy_image_path)\n",
    "    \n",
    "    # Convert to PyTorch tensor and add batch dimension\n",
    "    input_tensor = torch.from_numpy(img_np).permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Get raw prediction (logits)\n",
    "        logits = model(input_tensor)\n",
    "        # Convert to probabilities -> binary mask\n",
    "        pred_mask = (torch.sigmoid(logits) > 0.5).float()\n",
    "        \n",
    "    # Remove batch dimension and move to CPU\n",
    "    pred_mask = pred_mask.squeeze(0).cpu().numpy()\n",
    "    \n",
    "    return pred_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a03381-0589-4e40-9898-5d780a9c2867",
   "metadata": {},
   "source": [
    "## 4. Creating Sample Images for App Deployment & Testing the Pipeline\n",
    "This cell takes a few images from our test set and saves them as user-friendly .png files for the application demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c239dc8a-ffd3-48e3-95fb-c05b102c3466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating 5 sample files... ---\n",
      "Saved model input file: ../streamlit_app/sample_images\\sample_1_image.npy\n",
      "Saved model input file: ../streamlit_app/sample_images\\sample_2_image.npy\n",
      "Saved model input file: ../streamlit_app/sample_images\\sample_3_image.npy\n",
      "Saved model input file: ../streamlit_app/sample_images\\sample_4_image.npy\n",
      "Saved model input file: ../streamlit_app/sample_images\\sample_5_image.npy\n",
      "\n",
      "--- Sample mapping saved to: ../streamlit_app/sample_images\\sample_mapping.json ---\n",
      "\n",
      "--- All sample files created successfully. ---\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# Define the directory to save sample images\n",
    "SAMPLE_IMAGES_DIR = \"../streamlit_app/sample_images\"\n",
    "os.makedirs(SAMPLE_IMAGES_DIR, exist_ok=True)\n",
    "\n",
    "# --- This is the updated logic ---\n",
    "\n",
    "# Get a list of all possible .npy files from your processed data\n",
    "processed_files = glob.glob(\"../data/processed/*_image.npy\")\n",
    "sample_mapping = {}\n",
    "num_samples_to_create = 5 # You can change this number\n",
    "\n",
    "print(f\"--- Creating {num_samples_to_create} sample files... ---\")\n",
    "\n",
    "for i in range(num_samples_to_create):\n",
    "    # 1. Select a random .npy file\n",
    "    random_npy_path = random.choice(processed_files)\n",
    "    img_array = np.load(random_npy_path)\n",
    "\n",
    "    # 2. Define a new, simple filename for the .npy file\n",
    "    new_npy_filename = f\"sample_{i+1}_image.npy\"\n",
    "    new_npy_path = os.path.join(SAMPLE_IMAGES_DIR, new_npy_filename)\n",
    "\n",
    "    # 3. Save the actual .npy array into the streamlit_app/sample_images directory\n",
    "    np.save(new_npy_path, img_array)\n",
    "    print(f\"Saved model input file: {new_npy_path}\")\n",
    "\n",
    "    # 4. Update the mapping to use the new simple filename\n",
    "    sample_mapping[f\"Sample {i+1}\"] = new_npy_filename\n",
    "\n",
    "\n",
    "# --- Save the updated mapping file ---\n",
    "\n",
    "mapping_path = os.path.join(SAMPLE_IMAGES_DIR, 'sample_mapping.json')\n",
    "with open(mapping_path, 'w') as f:\n",
    "    json.dump(sample_mapping, f, indent=2)\n",
    "\n",
    "print(f\"\\n--- Sample mapping saved to: {mapping_path} ---\")\n",
    "print(\"\\n--- All sample files created successfully. ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "end_markdown_nb4",
   "metadata": {},
   "source": [
    "## End of Notebook 4\n",
    "\n",
    "This concludes our inference preparation. We have successfully:\n",
    "- Loaded our best-performing `ResNetUNet` model.\n",
    "- Built and tested a robust `predict` function that handles the full preprocessing and inference pipeline.\n",
    "\n",
    "We are now fully prepared to build the interactive Streamlit application."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
