{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro_markdown_nb4",
   "metadata": {},
   "source": [
    "# Notebook 4: Inference and App Preparation\n",
    "\n",
    "### Objectives:\n",
    "1.  **Load the Best Model:** Load the saved weights of our winning model (`ResNetUNet`).\n",
    "2.  **Create an Inference Pipeline:** Develop a robust function that takes a single image file, preprocesses it, and runs it through the model to get a segmentation mask.\n",
    "3.  **Test the Pipeline:** Verify that our inference function works correctly on a sample image, creating the final logic we'll use in our Streamlit application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup_imports_markdown_nb4",
   "metadata": {},
   "source": [
    "## 1. Setup, Imports, and Path Definitions\n",
    "\n",
    "First, we import the necessary libraries and define our project paths. We also import our model architectures from the `src` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup_imports_code_nb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil  # Added for copying files\n",
    "\n",
    "# --- Define Project Directories ---\n",
    "try:\n",
    "    ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "except NameError:\n",
    "    ROOT_DIR = os.path.abspath(os.path.join(os.path.dirname('__file__'), '..'))\n",
    "\n",
    "# --- Add Project Root to Python Path ---\n",
    "if ROOT_DIR not in sys.path:\n",
    "    sys.path.append(ROOT_DIR)\n",
    "\n",
    "print(f\"Project Root added to path: {ROOT_DIR}\")\n",
    "\n",
    "# --- Import our custom models ---\n",
    "from src.models import BaselineUNet, ResNetUNet, TransUNet\n",
    "\n",
    "MODELS_DIR = os.path.join(ROOT_DIR, 'models')\n",
    "FIGURES_DIR = os.path.join(ROOT_DIR, 'figures')\n",
    "\n",
    "# --- Set Device ---\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Root Directory: {ROOT_DIR}\")\n",
    "print(f\"Models Directory: {MODELS_DIR}\")\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_model_markdown_nb4",
   "metadata": {},
   "source": [
    "## 2. Load the Best Trained Model\n",
    "\n",
    "Based on our benchmark results, the `ResNetUNet` was the clear winner. We will now load its saved weights into a model instance and set it to evaluation mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_model_code_nb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_MODEL_NAME = 'ResNetUNet'\n",
    "model_path = os.path.join(MODELS_DIR, f'{BEST_MODEL_NAME}_best_model.pth')\n",
    "\n",
    "# Instantiate the model architecture\n",
    "model = ResNetUNet(in_channels=4, out_channels=1).to(DEVICE)\n",
    "\n",
    "# Load the saved weights\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device(DEVICE)))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "print(f\"Successfully loaded best model: {BEST_MODEL_NAME} from {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inference_pipeline_markdown_nb4",
   "metadata": {},
   "source": [
    "## 3. Create the Inference Pipeline\n",
    "\n",
    "Here we create a single, powerful function called `predict`. This function encapsulates all the necessary steps: opening an image, preprocessing it to match the training format, running inference, and post-processing the output mask. This is the core function we will use in our Streamlit app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inference_pipeline_code_nb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================\n",
    "#             CREATE THE INFERENCE PIPELINE (CORRECTED)\n",
    "# =========================================================================\n",
    "\n",
    "def predict(model, npy_image_path, device):\n",
    "    \"\"\"\n",
    "    Runs the full inference pipeline on a single, preprocessed .npy image slice.\n",
    "    \"\"\"\n",
    "    # Load the correctly preprocessed numpy array\n",
    "    img_np = np.load(npy_image_path)\n",
    "    \n",
    "    # Convert to PyTorch tensor and add batch dimension\n",
    "    input_tensor = torch.from_numpy(img_np).permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Get raw prediction (logits)\n",
    "        logits = model(input_tensor)\n",
    "        # Convert to probabilities -> binary mask\n",
    "        pred_mask = (torch.sigmoid(logits) > 0.5).float()\n",
    "        \n",
    "    # Remove batch dimension and move to CPU\n",
    "    pred_mask = pred_mask.squeeze(0).cpu().numpy()\n",
    "    \n",
    "    return pred_mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a03381-0589-4e40-9898-5d780a9c2867",
   "metadata": {},
   "source": [
    "## 4. Creating Sample Images for App Deployment & Testing the Pipeline\n",
    "This cell takes a few images from our test set and saves them as user-friendly .png files for the application demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c239dc8a-ffd3-48e3-95fb-c05b102c3466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================\n",
    "#       FINAL CELL: CREATE SAMPLES & TEST INFERENCE PIPELINE (DEPLOYMENT READY)\n",
    "# This version COPIES the .npy files to streamlit_app/sample_images for deployment\n",
    "# =========================================================================\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from glob import glob\n",
    "import random\n",
    "import json\n",
    "\n",
    "print(\"--- Creating Sample Images & Copying Data for Deployment ---\")\n",
    "\n",
    "# --- 1. Re-create the test set file list ---\n",
    "PROCESSED_DATA_DIR = os.path.join(ROOT_DIR, 'data', 'processed')\n",
    "all_files = glob(os.path.join(PROCESSED_DATA_DIR, \"*_image.npy\"))\n",
    "_, test_files = train_test_split(all_files, test_size=0.15, random_state=42)\n",
    "\n",
    "# --- 2. Define the sample directory ---\n",
    "SAMPLE_IMAGES_DIR = os.path.join(ROOT_DIR, 'streamlit_app', 'sample_images')\n",
    "os.makedirs(SAMPLE_IMAGES_DIR, exist_ok=True)\n",
    "print(f\"Samples will be saved to: {SAMPLE_IMAGES_DIR}\")\n",
    "\n",
    "# --- 3. Select random test files ---\n",
    "num_samples_to_create = 5\n",
    "random_test_npy_paths = random.sample(test_files, num_samples_to_create)\n",
    "\n",
    "# --- 4. Loop, Copy Files, Create PNGs, Predict, and Visualize ---\n",
    "sample_mapping = {}\n",
    "\n",
    "for i, original_npy_path in enumerate(random_test_npy_paths):\n",
    "    \n",
    "    # --- a. Copy the .npy files to streamlit_app/sample_images ---\n",
    "    # Copy image file\n",
    "    image_filename = f\"sample_{i+1}_image.npy\"\n",
    "    mask_filename = f\"sample_{i+1}_mask.npy\"\n",
    "    \n",
    "    copied_image_path = os.path.join(SAMPLE_IMAGES_DIR, image_filename)\n",
    "    copied_mask_path = os.path.join(SAMPLE_IMAGES_DIR, mask_filename)\n",
    "    \n",
    "    # Copy the actual .npy files\n",
    "    shutil.copy2(original_npy_path, copied_image_path)\n",
    "    shutil.copy2(original_npy_path.replace(\"_image.npy\", \"_mask.npy\"), copied_mask_path)\n",
    "    \n",
    "    print(f\"Copied: {os.path.basename(original_npy_path)} -> {image_filename}\")\n",
    "    \n",
    "    # --- b. Run INFERENCE on the COPIED .npy file ---\n",
    "    predicted_mask_array = predict(model, copied_image_path, DEVICE)\n",
    "    \n",
    "    # --- c. Create the .png files for visualization ---\n",
    "    mri_slice = np.load(copied_image_path)[:, :, 0]  # T1c channel\n",
    "    mask_slice = (np.load(copied_mask_path) > 0).astype(np.uint8)\n",
    "\n",
    "    img_to_save = Image.fromarray((mri_slice * 255).astype(np.uint8))\n",
    "    mask_to_save = Image.fromarray(mask_slice * 255)\n",
    "\n",
    "    img_save_path = os.path.join(SAMPLE_IMAGES_DIR, f\"sample_{i+1}.png\")\n",
    "    mask_save_path = os.path.join(SAMPLE_IMAGES_DIR, f\"sample_{i+1}_mask.png\")\n",
    "    img_to_save.save(img_save_path)\n",
    "    mask_to_save.save(mask_save_path)\n",
    "    \n",
    "    # --- d. Update mapping to point to copied files (deployment-ready paths) ---\n",
    "    sample_mapping[f\"sample_{i+1}.png\"] = {\n",
    "        \"image_npy\": image_filename,  # Just filename, not full path\n",
    "        \"mask_npy\": mask_filename,\n",
    "        \"original_source\": os.path.basename(original_npy_path)\n",
    "    }\n",
    "    \n",
    "    # --- e. Visualize the result ---\n",
    "    print(f\"\\n--- Verification for sample_{i+1}.png ---\")\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    ax1.imshow(img_to_save, cmap='bone'); ax1.set_title('Input Image'); ax1.axis('off')\n",
    "    ax2.imshow(mask_to_save, cmap='magma'); ax2.set_title('Ground Truth Mask'); ax2.axis('off')\n",
    "    ax3.imshow(predicted_mask_array.squeeze(), cmap='magma'); ax3.set_title(f'Predicted Mask'); ax3.axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# --- 5. Save the deployment-ready mapping ---\n",
    "mapping_path = os.path.join(SAMPLE_IMAGES_DIR, 'sample_mapping.json')\n",
    "with open(mapping_path, 'w') as f:\n",
    "    json.dump(sample_mapping, f, indent=2)\n",
    "\n",
    "print(f\"\\n--- Sample mapping saved to: {mapping_path} ---\")\n",
    "print(\"Deployment-ready mapping contents:\")\n",
    "for png, info in sample_mapping.items():\n",
    "    print(f\"  {png} -> {info['image_npy']} (from {info['original_source']})\")\n",
    "\n",
    "# --- 6. Show what files are now in the sample_images directory ---\n",
    "print(f\"\\n--- Files in {SAMPLE_IMAGES_DIR} (ready for deployment): ---\")\n",
    "for file in sorted(os.listdir(SAMPLE_IMAGES_DIR)):\n",
    "    file_path = os.path.join(SAMPLE_IMAGES_DIR, file)\n",
    "    size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
    "    print(f\"  {file} ({size_mb:.2f} MB)\")\n",
    "\n",
    "print(f\"\\n--- {num_samples_to_create} samples created and copied for deployment! ---\")\n",
    "print(\"âœ… All .npy files are now in streamlit_app/sample_images and can be deployed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "end_markdown_nb4",
   "metadata": {},
   "source": [
    "## End of Notebook 4\n",
    "\n",
    "This concludes our inference preparation. We have successfully:\n",
    "- Loaded our best-performing `ResNetUNet` model.\n",
    "- Built and tested a robust `predict` function that handles the full preprocessing and inference pipeline.\n",
    "\n",
    "We are now fully prepared to build the interactive Streamlit application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62640f76",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
