{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro_markdown",
   "metadata": {},
   "source": [
    "# Notebook 3: Model Training and Benchmarking\n",
    "\n",
    "### Objectives:\n",
    "1.  **Set up the Training Environment:** Configure hyperparameters, data loaders, models, and loss functions.\n",
    "2.  **Train and Benchmark Models:** Train our three candidate models (`BaselineUNet`, `ResNetUNet`, `TransUNet`) on the processed dataset.\n",
    "3.  **Evaluate Performance:** Analyze training progress with loss curves and evaluate final models on the unseen test set using the Dice score.\n",
    "4.  **Visualize Results:** Create high-quality visualizations of model predictions for the final report and presentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup_imports_markdown",
   "metadata": {},
   "source": [
    "## 1. Setup, Imports, and Path Definitions\n",
    "\n",
    "We begin by importing all necessary libraries and defining the project's directory structure. This ensures our environment is correctly configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d109089-1aff-4f45-ac6a-90215139b8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Root Directory to Path: D:\\Coding\\GitHub\\MRI-Tumor-Segmentation\n",
      "Successfully imported custom models.\n",
      "Processed Data Directory: D:\\Coding\\GitHub\\MRI-Tumor-Segmentation\\data\\processed\n",
      "Saved Models Directory: D:\\Coding\\GitHub\\MRI-Tumor-Segmentation\\models\n",
      "Saved Figures Directory: D:\\Coding\\GitHub\\MRI-Tumor-Segmentation\\figures\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys  # Import the sys module to manipulate Python's path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import random\n",
    "\n",
    "# --- Define and Add Root Directory to Path ---\n",
    "# This is the crucial step to fix the ModuleNotFoundError.\n",
    "# When running a notebook from the 'notebooks' folder, we need to tell Python\n",
    "# where to find our 'src' module in the parent directory.\n",
    "ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if ROOT_DIR not in sys.path:\n",
    "    sys.path.append(ROOT_DIR)\n",
    "    print(f\"Added Root Directory to Path: {ROOT_DIR}\")\n",
    "\n",
    "# --- Import custom models from src ---\n",
    "# This will now work correctly\n",
    "from src.models import BaselineUNet, ResNetUNet, TransUNet\n",
    "print(\"Successfully imported custom models.\")\n",
    "\n",
    "# --- Define Project Directories ---\n",
    "PROCESSED_DATA_DIR = os.path.join(ROOT_DIR, 'data', 'processed')\n",
    "MODELS_DIR = os.path.join(ROOT_DIR, 'models')\n",
    "FIGURES_DIR = os.path.join(ROOT_DIR, 'figures')\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(FIGURES_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Processed Data Directory: {PROCESSED_DATA_DIR}\")\n",
    "print(f\"Saved Models Directory: {MODELS_DIR}\")\n",
    "print(f\"Saved Figures Directory: {FIGURES_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config_markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration & Hyperparameters\n",
    "\n",
    "This cell contains all the key parameters for our training run. To benchmark a different model, simply change the `MODEL_TO_TRAIN` variable and re-run the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "config_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n"
     ]
    }
   ],
   "source": [
    "# --- CONFIGURATION & HYPERPARAMETERS ---\n",
    "\n",
    "# Choose which model to train: 'BaselineUNet', 'ResNetUNet', or 'TransUNet'\n",
    "MODEL_TO_TRAIN = 'ResNetUNet'\n",
    "\n",
    "# Data parameters\n",
    "TEST_SPLIT_SIZE = 0.15\n",
    "VALIDATION_SPLIT_SIZE = 0.15 # From the remaining data after test split\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Training parameters\n",
    "LEARNING_RATE = 1e-4\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 25 # Start with a reasonable number, can be increased\n",
    "\n",
    "# System parameters\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"DEVICE: {DEVICE}\")\n",
    "NUM_WORKERS = 0 # os.cpu_count()\n",
    "PIN_MEMORY = True\n",
    "\n",
    "# Ensure reproducibility\n",
    "random.seed(RANDOM_STATE)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(RANDOM_STATE)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dataset_markdown",
   "metadata": {},
   "source": [
    "## 3. Custom PyTorch Dataset\n",
    "\n",
    "We define a custom `Dataset` class. This is the standard PyTorch way to handle data. It loads data efficiently from disk slice by slice, which is essential for managing memory when working with large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dataset_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "class BrainMRIDataset(Dataset):\n",
    "    def __init__(self, file_list, cache_size=8000): # Cache can hold 8000 items\n",
    "        self.file_list = file_list\n",
    "        self.cache_size = cache_size\n",
    "        # Using an OrderedDict to implement a simple LRU (Least Recently Used) cache\n",
    "        self.cache = collections.OrderedDict()\n",
    "        \n",
    "        print(f\"Initialized dataset with {len(file_list)} files.\")\n",
    "        print(f\"Cache size set to {cache_size} items.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # --- Check if the item is in the cache ---\n",
    "        if idx in self.cache:\n",
    "            # Move the accessed item to the end to mark it as recently used\n",
    "            self.cache.move_to_end(idx)\n",
    "            return self.cache[idx]\n",
    "        \n",
    "        # --- If not in cache (cache miss), load from disk ---\n",
    "        image_path = self.file_list[idx]\n",
    "        mask_path = image_path.replace(\"_image.npy\", \"_mask.npy\")\n",
    "        \n",
    "        image = np.load(image_path).astype(np.float32)\n",
    "        mask = np.load(mask_path).astype(np.float32)\n",
    "\n",
    "        image_tensor = torch.from_numpy(image).permute(2, 0, 1)\n",
    "        mask_tensor = torch.from_numpy(mask).unsqueeze(0)\n",
    "        \n",
    "        # --- Manage cache size ---\n",
    "        if len(self.cache) >= self.cache_size:\n",
    "            # Pop the least recently used item (the first item in the dict)\n",
    "            self.cache.popitem(last=False)\n",
    "        \n",
    "        # Add the newly loaded item to the cache\n",
    "        self.cache[idx] = (image_tensor, mask_tensor)\n",
    "        \n",
    "        return image_tensor, mask_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split_markdown",
   "metadata": {},
   "source": [
    "## 4. Data Splitting and Loaders\n",
    "\n",
    "We split our list of processed slices into training, validation, and test sets. This is a critical step to ensure we can evaluate our model's generalization ability on unseen data. Then, we wrap these sets in `DataLoader` objects, which handle batching and shuffling automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "split_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized dataset with 7484 files.\n",
      "Cache size set to 8000 items.\n",
      "Initialized dataset with 1604 files.\n",
      "Cache size set to 8000 items.\n",
      "Initialized dataset with 1604 files.\n",
      "Cache size set to 8000 items.\n",
      "--- Data Splitting Summary ---\n",
      "Total slices: 10692\n",
      "Training set:   7484 slices (70.0%)\n",
      "Validation set: 1604 slices (15.0%)\n",
      "Test set:       1604 slices (15.0%)\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Get all image file paths\n",
    "all_files = glob(os.path.join(PROCESSED_DATA_DIR, \"*_image.npy\"))\n",
    "\n",
    "# First, split into training+validation and test sets\n",
    "train_val_files, test_files = train_test_split(\n",
    "    all_files, test_size=TEST_SPLIT_SIZE, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Then, split the training+validation set into training and validation sets\n",
    "relative_val_size = VALIDATION_SPLIT_SIZE / (1 - TEST_SPLIT_SIZE)\n",
    "train_files, val_files = train_test_split(\n",
    "    train_val_files, test_size=relative_val_size, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Create Dataset objects\n",
    "train_dataset = BrainMRIDataset(train_files)\n",
    "val_dataset = BrainMRIDataset(val_files)\n",
    "test_dataset = BrainMRIDataset(test_files)\n",
    "\n",
    "# Create DataLoader objects\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "\n",
    "# --- Print a summary of the data splitting ---\n",
    "print(\"--- Data Splitting Summary ---\")\n",
    "print(f\"Total slices: {len(all_files)}\")\n",
    "print(f\"Training set:   {len(train_files)} slices ({len(train_files)/len(all_files):.1%})\")\n",
    "print(f\"Validation set: {len(val_files)} slices ({len(val_files)/len(all_files):.1%})\")\n",
    "print(f\"Test set:       {len(test_files)} slices ({len(test_files)/len(all_files):.1%})\")\n",
    "print(\"------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loss_markdown",
   "metadata": {},
   "source": [
    "## 5. Loss Function and Evaluation Metric\n",
    "\n",
    "We define our loss function, which is what the model tries to minimize. For segmentation, a combination of Binary Cross-Entropy (BCE) and Dice Loss is a powerful choice. \n",
    "- **BCE Loss:** Good for pixel-wise classification.\n",
    "- **Dice Loss:** Directly optimizes the Dice coefficient, our main evaluation metric, which is excellent for handling class imbalance (more non-tumor pixels than tumor pixels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "loss_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1e-6):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_pred = y_pred.contiguous()\n",
    "        y_true = y_true.contiguous()\n",
    "\n",
    "        intersection = (y_pred * y_true).sum(dim=2).sum(dim=2)\n",
    "        dice = (2. * intersection + self.smooth) / (y_pred.sum(dim=2).sum(dim=2) + y_true.sum(dim=2).sum(dim=2) + self.smooth)\n",
    "        \n",
    "        return 1 - dice.mean()\n",
    "\n",
    "def dice_coefficient(y_pred, y_true, smooth=1e-6):\n",
    "    y_pred = (y_pred > 0.5).float() # Binarize the prediction\n",
    "    intersection = (y_pred * y_true).sum()\n",
    "    dice = (2. * intersection + smooth) / (y_pred.sum() + y_true.sum() + smooth)\n",
    "    return dice.item()\n",
    "\n",
    "# Combined Loss Function\n",
    "def combined_loss(y_pred, y_true):\n",
    "    bce = nn.BCEWithLogitsLoss()(y_pred, y_true) # BCEWithLogitsLoss is more stable\n",
    "    dice = DiceLoss()(torch.sigmoid(y_pred), y_true)\n",
    "    return bce + dice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training_loop_markdown",
   "metadata": {},
   "source": [
    "## 6. Training & Validation Loop\n",
    "\n",
    "This is the core of our notebook. We define two functions:\n",
    "1. `train_fn`: Handles one epoch of training. It iterates through the `train_loader`, performs forward and backward passes, and updates the model's weights.\n",
    "2. `evaluate_fn`: Handles model evaluation on the validation or test set. It calculates the loss and Dice score without updating the model.\n",
    "\n",
    "The main loop then orchestrates the training over multiple epochs, tracks performance, and saves the best model based on validation Dice score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "training_loop_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(loader, model, optimizer, loss_fn, scaler):\n",
    "    loop = tqdm(loader, desc=\"Training\")\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        data = data.to(device=DEVICE)\n",
    "        targets = targets.to(device=DEVICE)\n",
    "\n",
    "        # Forward\n",
    "        with torch.cuda.amp.autocast():\n",
    "            predictions = model(data)\n",
    "            loss = loss_fn(predictions, targets)\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    \n",
    "    return running_loss / len(loader)\n",
    "\n",
    "def evaluate_fn(loader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    loop = tqdm(loader, desc=\"Evaluating\")\n",
    "    val_loss = 0.0\n",
    "    val_dice = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, targets in loop:\n",
    "            data = data.to(device=device)\n",
    "            targets = targets.to(device=device)\n",
    "            \n",
    "            predictions = model(data)\n",
    "            loss = loss_fn(predictions, targets)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            # Calculate dice score\n",
    "            preds_sigmoid = torch.sigmoid(predictions)\n",
    "            dice = dice_coefficient(preds_sigmoid, targets)\n",
    "            val_dice += dice\n",
    "            loop.set_postfix(dice=dice)\n",
    "            \n",
    "    model.train()\n",
    "    return val_loss / len(loader), val_dice / len(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "run_training_markdown",
   "metadata": {},
   "source": [
    "## 7. Run the Training\n",
    "\n",
    "Now, we bring everything together. We select the model based on our configuration, initialize the optimizer, and start the main training loop. We will save the model with the best validation Dice score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_training_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmad\\AppData\\Local\\Temp\\ipykernel_13976\\2765822528.py:15: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE == \"cuda\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Run Initiated ---\n",
      "Model: ResNetUNet\n",
      "Epochs: 25\n",
      "Batch Size: 16\n",
      "Learning Rate: 0.0001\n",
      "Device: cuda\n",
      "------------------------------\n",
      "\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                            | 0/468 [00:00<?, ?it/s]C:\\Users\\ahmad\\AppData\\Local\\Temp\\ipykernel_13976\\908607570.py:10: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|███████████████████████████████████████| 468/468 [14:07<00:00,  1.81s/it, loss=1.53]\n",
      "Evaluating: 100%|████████████████████████████████████| 101/101 [03:39<00:00,  2.17s/it, dice=0.126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5791 | Val Loss: 1.4839 | Val Dice: 0.1432\n",
      "Validation Dice score improved from -1.0000 to 0.1432. Saving model to D:\\Coding\\GitHub\\MRI-Tumor-Segmentation\\models\\ResNetUNet_best_model.pth\n",
      "\n",
      "Epoch 2/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████| 468/468 [02:40<00:00,  2.91it/s, loss=1.48]\n",
      "Evaluating: 100%|████████████████████████████████████| 101/101 [00:08<00:00, 11.95it/s, dice=0.126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4795 | Val Loss: 1.4703 | Val Dice: 0.1432\n",
      "\n",
      "Epoch 3/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████| 468/468 [01:03<00:00,  7.36it/s, loss=1.44]\n",
      "Evaluating: 100%|████████████████████████████████████| 101/101 [00:07<00:00, 13.20it/s, dice=0.126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4726 | Val Loss: 1.4668 | Val Dice: 0.1432\n",
      "\n",
      "Epoch 4/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████| 468/468 [00:58<00:00,  8.03it/s, loss=1.51]\n",
      "Evaluating: 100%|████████████████████████████████████| 101/101 [00:07<00:00, 12.73it/s, dice=0.126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4704 | Val Loss: 1.4651 | Val Dice: 0.1432\n",
      "\n",
      "Epoch 5/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████| 468/468 [00:54<00:00,  8.54it/s, loss=1.48]\n",
      "Evaluating: 100%|████████████████████████████████████| 101/101 [00:07<00:00, 13.66it/s, dice=0.126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4692 | Val Loss: 1.4641 | Val Dice: 0.1432\n",
      "\n",
      "Epoch 6/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████| 468/468 [00:55<00:00,  8.43it/s, loss=1.55]\n",
      "Evaluating: 100%|████████████████████████████████████| 101/101 [00:07<00:00, 13.61it/s, dice=0.126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4685 | Val Loss: 1.4638 | Val Dice: 0.1432\n",
      "Validation Dice score improved from 0.1432 to 0.1432. Saving model to D:\\Coding\\GitHub\\MRI-Tumor-Segmentation\\models\\ResNetUNet_best_model.pth\n",
      "\n",
      "Epoch 7/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████| 468/468 [00:54<00:00,  8.59it/s, loss=1.54]\n",
      "Evaluating: 100%|████████████████████████████████████| 101/101 [00:07<00:00, 13.47it/s, dice=0.126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4681 | Val Loss: 1.4634 | Val Dice: 0.1432\n",
      "Validation Dice score improved from 0.1432 to 0.1432. Saving model to D:\\Coding\\GitHub\\MRI-Tumor-Segmentation\\models\\ResNetUNet_best_model.pth\n",
      "\n",
      "Epoch 8/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████| 468/468 [00:55<00:00,  8.38it/s, loss=1.45]\n",
      "Evaluating: 100%|████████████████████████████████████| 101/101 [00:07<00:00, 12.91it/s, dice=0.126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4678 | Val Loss: 1.4633 | Val Dice: 0.1432\n",
      "Validation Dice score improved from 0.1432 to 0.1432. Saving model to D:\\Coding\\GitHub\\MRI-Tumor-Segmentation\\models\\ResNetUNet_best_model.pth\n",
      "\n",
      "Epoch 9/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|███████▎                                | 85/468 [00:10<00:45,  8.40it/s, loss=1.46]"
     ]
    }
   ],
   "source": [
    "# --- Model Selection ---\n",
    "if MODEL_TO_TRAIN == 'BaselineUNet':\n",
    "    model = BaselineUNet(in_channels=4, out_channels=1).to(DEVICE)\n",
    "elif MODEL_TO_TRAIN == 'ResNetUNet':\n",
    "    model = ResNetUNet(in_channels=4, out_channels=1).to(DEVICE)\n",
    "elif MODEL_TO_TRAIN == 'TransUNet':\n",
    "    model = TransUNet(in_channels=4, out_channels=1).to(DEVICE)\n",
    "else:\n",
    "    raise ValueError(f\"Unknown model: {MODEL_TO_TRAIN}\")\n",
    "\n",
    "# --- Optimizer, Loss, and Scaler ---\n",
    "loss_fn = combined_loss # Our custom combined loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "# THE FIX IS HERE: Corrected class name and enabled only for CUDA\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE == \"cuda\"))\n",
    "\n",
    "# --- Training History and Best Model State ---\n",
    "history = {'train_loss': [], 'val_loss': [], 'val_dice': []}\n",
    "best_val_dice = -1.0\n",
    "model_save_path = os.path.join(MODELS_DIR, f'{MODEL_TO_TRAIN}_best_model.pth')\n",
    "\n",
    "# --- Print Training Configuration ---\n",
    "print(\"--- Training Run Initiated ---\")\n",
    "print(f\"Model: {MODEL_TO_TRAIN}\")\n",
    "print(f\"Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(\"------------------------------\")\n",
    "\n",
    "# --- Main Training Loop ---\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    train_loss = train_fn(train_loader, model, optimizer, loss_fn, scaler)\n",
    "    val_loss, val_dice = evaluate_fn(val_loader, model, loss_fn, DEVICE)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Dice: {val_dice:.4f}\")\n",
    "\n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_dice'].append(val_dice)\n",
    "\n",
    "    # Save the best model\n",
    "    if val_dice > best_val_dice:\n",
    "        print(f\"Validation Dice score improved from {best_val_dice:.4f} to {val_dice:.4f}. Saving model to {model_save_path}\")\n",
    "        best_val_dice = val_dice\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "print(\"\\n--- Training Finished ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualize_training_markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Training Progress\n",
    "\n",
    "Plotting the training and validation metrics over time is crucial for understanding how our model learned. It helps us spot issues like overfitting and determine if the model trained for a sufficient number of epochs. These plots are essential for our final presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize_training_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
    "fig.suptitle(f'Training History for {MODEL_TO_TRAIN}', fontsize=16)\n",
    "\n",
    "# Plotting Loss\n",
    "ax1.plot(history['train_loss'], label='Training Loss')\n",
    "ax1.plot(history['val_loss'], label='Validation Loss')\n",
    "ax1.set_title('Loss vs. Epochs')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Plotting Validation Dice Score\n",
    "ax2.plot(history['val_dice'], label='Validation Dice Score', color='green')\n",
    "ax2.set_title('Validation Dice Score vs. Epochs')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Dice Score')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "# Save the figure\n",
    "figure_path = os.path.join(FIGURES_DIR, f'{MODEL_TO_TRAIN}_training_history.png')\n",
    "plt.savefig(figure_path, dpi=300)\n",
    "print(f\"Training history plot saved to: {figure_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluate_markdown",
   "metadata": {},
   "source": [
    "## 9. Final Evaluation on Test Set\n",
    "\n",
    "Now for the ultimate test. We load our best-performing model (saved during training) and evaluate its performance on the completely held-out test set. This gives us the final, unbiased measure of our model's quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluate_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "\n",
    "print(f\"--- Evaluating Best {MODEL_TO_TRAIN} on Test Set ---\")\n",
    "test_loss, test_dice = evaluate_fn(test_loader, model, loss_fn, DEVICE)\n",
    "\n",
    "print(\"\\n--- Final Test Set Performance ---\")\n",
    "print(f\"Model: {MODEL_TO_TRAIN}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Dice Score: {test_dice:.4f}\")\n",
    "print(\"------------------------------------\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualize_results_markdown",
   "metadata": {},
   "source": [
    "## 10. Visualize Predictions\n",
    "\n",
    "Numbers are great, but visualizations are powerful. Here we take a few random samples from our test set and create a side-by-side comparison of the input image, the ground truth mask, and our model's prediction. This provides clear, intuitive proof of our model's capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize_results_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 5\n",
    "model.eval()\n",
    "\n",
    "fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5 * num_samples))\n",
    "fig.suptitle(f'Sample Predictions for {MODEL_TO_TRAIN} on Test Set', fontsize=20, y=1.02)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(num_samples):\n",
    "        # Get a random sample from the test set\n",
    "        idx = random.randint(0, len(test_dataset) - 1)\n",
    "        image, mask = test_dataset[idx]\n",
    "        image_gpu = image.unsqueeze(0).to(DEVICE)\n",
    "        \n",
    "        # Get model prediction\n",
    "        pred_mask = model(image_gpu)\n",
    "        pred_mask = (torch.sigmoid(pred_mask) > 0.5).float().cpu().squeeze(0)\n",
    "        \n",
    "        # Prepare for plotting (C, H, W) -> (H, W, C) for image\n",
    "        image = image.permute(1, 2, 0).numpy()\n",
    "        mask = mask.squeeze(0).numpy()\n",
    "        pred_mask = pred_mask.squeeze(0).numpy()\n",
    "        \n",
    "        # We'll visualize one of the MRI channels, e.g., T1c (channel 0)\n",
    "        display_image = image[:, :, 0]\n",
    "        \n",
    "        # Plot Input Image\n",
    "        axes[i, 0].imshow(display_image, cmap='bone')\n",
    "        axes[i, 0].set_title(f'Sample {i+1}: Input (T1c)')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # Plot Ground Truth Mask\n",
    "        axes[i, 1].imshow(mask, cmap='magma')\n",
    "        axes[i, 1].set_title(f'Sample {i+1}: Ground Truth')\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # Plot Predicted Mask\n",
    "        axes[i, 2].imshow(pred_mask, cmap='magma')\n",
    "        axes[i, 2].set_title(f'Sample {i+1}: Prediction')\n",
    "        axes[i, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "figure_path = os.path.join(FIGURES_DIR, f'{MODEL_TO_TRAIN}_test_predictions.png')\n",
    "plt.savefig(figure_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"\\nPrediction visualization saved to: {figure_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "end_markdown",
   "metadata": {},
   "source": [
    "## End of Notebook 3\n",
    "\n",
    "This concludes the model training and benchmarking phase. We have successfully:\n",
    "- Trained one of our selected model architectures.\n",
    "- Saved the best performing weights.\n",
    "- Plotted the training history to analyze its learning behavior.\n",
    "- Evaluated its final performance on the unseen test set.\n",
    "- Visualized its segmentation capabilities on sample images.\n",
    "\n",
    "To benchmark the other models, simply change the `MODEL_TO_TRAIN` variable at the top of this notebook and re-run all cells. Once all models are benchmarked, we will be ready to proceed to **Notebook 4: Inference and App Preparation**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
